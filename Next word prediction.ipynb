{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df07a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMportant libraries to install \n",
    "import numpy as np\n",
    "#if not installed\n",
    "#!pip install tensorflow \n",
    "#!pip install keras \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f025322",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '1661-0.txt'\n",
    "text = open(path, encoding='utf8').read().lower()\n",
    "print('corpus length:', len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f6b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the text file \n",
    "with open('1661-0.txt', 'r',encoding='utf-8') as inp:\n",
    "    y = inp.read().lower()\n",
    "print('corpus length:', len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f56bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I will split the dataset into each word in order but without the presence of some special characters.\n",
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "words = tokenizer.tokenize(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc6c24",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = np.unique(words)\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here I will define a Word length which will represent the number of previous words that will determine our next word. \n",
    "I will define prev words to keep five previous words and their corresponding next words in the list of next words\n",
    "\"\"\"\n",
    "WORD_LENGTH = 5\n",
    "prev_words = []\n",
    "next_words = []\n",
    "for i in range(len(words) - WORD_LENGTH):\n",
    "    prev_words.append(words[i:i + WORD_LENGTH])\n",
    "    next_words.append(words[i + WORD_LENGTH])\n",
    "print(prev_words[0])\n",
    "print(next_words[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
    "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)\n",
    "for i, each_words in enumerate(prev_words):\n",
    "    for j, each_word in enumerate(each_words):\n",
    "        X[i, j, unique_word_index[each_word]] = 1\n",
    "    Y[i, unique_word_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f44e4",
   "metadata": {},
   "source": [
    "# Building the Recurrent Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628849c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
    "model.add(Dense(len(unique_words)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea875ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True).history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bce971",
   "metadata": {},
   "source": [
    "model.save('keras_next_word_model.h5')\n",
    "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
    "model = load_model('keras_next_word_model.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['acc'])\n",
    "plt.plot(history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f893c",
   "metadata": {},
   "source": [
    "# Testing Next Word Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a59792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
    "    for t, char in enumerate(text):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "    return x\n",
    "prepare_input(\"This is an example of input for our LSTM\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472bdc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        print(word)\n",
    "        x[0, t, unique_word_index[word]] = 1\n",
    "    return x\n",
    "prepare_input(\"It is not a lack\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a58a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I will create a function to return samples:\n",
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now I will create a function for next word prediction:\n",
    "def predict_completion(text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        \n",
    "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
    "            return completion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function is created to predict the next word until space is generated. It will do this by iterating the input, which will ask our RNN model and extract instances from it.\n",
    "\"\"\"\n",
    "def predict_completions(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in quotes:\n",
    "    seq = q[:40].lower()\n",
    "    print(seq)\n",
    "    print(predict_completions(seq, 5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d978d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
